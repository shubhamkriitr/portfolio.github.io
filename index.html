<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Shubham Kumar | Master's student in Computer Science | ETH Zurich | Indian Institute of Technology Roorkee">
    <meta name="author" content="Shubham Kumar">
    <meta http-equiv="keywords" content="Computer Vision, CV,AI,Machine Learning Engineer,ETH,Zurich,zurich,machine learning,ethz,ethz.ch,IIT,IIT Roorkee,IITR,IIT-R,Indian Institute of Technology,Indian Institute of Technology Roorkee,University,iit,iitr,technology,engineering,research,roorkee,academics,indian,institute,iitroorkee,university,b tech,b arch,doctorate,undergraduate,bharatiya,Shubham Kumar,CSE,EE,Computer Science,Computer Engineering,Deep Learning,Software Engineering,Data Science,Roorkee,Oracle,AI services,Research,Bangalore">
    <title>Shubham Kumar | M.Sc. Computer Science, ETH Zürich </title>

    <link rel="stylesheet" href="res/css/mystyle.css">
    <link rel="stylesheet" href="res/css/basics_v001.css">
    <link rel="icon" type="image/x-icon" href="./res/images/eth_logo.png">
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <script defer src="res/scripts/jquery-3.7.1.min.js"></script>
  </head>

 

  <!-- Added mx-3 class on top level for controling higher level margins -->
  <body class=" mx-3" >
    <script>
      function toggleNavBar() {
  
          console.log("hello");
          $("#elem-navbar-burger").toggleClass("is-active");
          $("#navbarBasicExample").toggleClass("is-active");
          
      }
  </script>
     <br/>
     <section>
      <div class="container">
        <nav class="navbar " role="navigation" aria-label="main navigation">
          <div class="navbar-brand">
            <!-- <a class="navbar-item" href="https://bulma.io">
              <img src="https://bulma.io/images/bulma-logo.png" width="112" height="28">
            </a> -->
        
            <a id="elem-navbar-burger" role="button" class="navbar-burger" aria-label="menu" aria-expanded="true" data-target="navbarBasicExample"
              onclick="toggleNavBar()">
              <span aria-hidden="true"></span>
              <span aria-hidden="true"></span>
              <span aria-hidden="true"></span>
            </a>
          </div>
        
          <div id="navbarBasicExample" class="navbar-menu">
            <div class="navbar-start">
              <a class="navbar-item" href="#elem-section-education">
                Education
              </a>
        
              <a class="navbar-item" href="#elem-section-work">
                Work Experience
              </a>
        
              <a class="navbar-item" href="#elem-section-research">
                Research
              </a>

              <a class="navbar-item" href="#elem-section-projects">
                Projects
              </a>
        

            </div>
        
            <div class="navbar-end">
              <!-- <div class="navbar-item">
                <div class="buttons">
                  <a class="button is-primary">
                    <strong>Sign up</strong>
                  </a>
                  <a class="button is-light">
                    Log in
                  </a>
                </div>
              </div> -->
            </div>
          </div>
        </nav>
      </div>
    </section>
    <hr/>

     <section>
      <div class="container">
        <div class="columns">
          <div class="column is-2">
            
              <div class="media " style="justify-content: center">
                  <figure class="image is-128x128"> 
                    <img src="res/images/profile_picture_01_30dpi.jpeg" class="is-rounded sk-profile-image" alt="Profile picture">
                  </figure>
              </div>

            </div>
            <div class="column has-text-centered is-7">
              <h1 class="is-size-1">Shubham Kumar</h1>
              <p class="">M.Sc. Computer Science @ ETH Zürich<span>, Master's thesis @ Disney Research | Studios</span></p>
            </div>
            <div class="column has-text-centered has-text-right-desktop">
              <p><span class="icon"><i class="fas fa-map-marker-alt"></i></span>Zürich, Switzerland</p>
              <p><a class="is-linkedin" title="https://www.linkedin.com/in/shubhamkumar101/" href="https://www.linkedin.com/in/shubhamkumar101/" target="_blank">
                <span class="icon">
                  <i class="fab fa-linkedin"></i>
                </span>
                <span>@shubhamkumar101</span>
              </a></p>
              <p><a class="is-github" title="https://github.com/shubhamkriitr" href="https://github.com/shubhamkriitr" target="_blank">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>@shubhamkriitr</span>
              </a></p>
            </div>
          </div>

          

        </div>
     </section>
     <br/>


     <div class="hr"></div>
     <section id="elem-section-education">
      <div class="container">
        <div class="columns">
          <div class="column is-12 is-offset-0 is-offset-1-mobile is-10-mobile">
            <div class="content">
              
              
              
              <!-- EDUCATION -->
              <br/>
              <div class="sk-section-heading">Education</div>
              <table>
                <thead>
                  <tr>
                    <th>Year</th>
                    <th>Degree/Program</th>
                    <th>Institution</th>
                    <!-- <th>CGPA/Percentage</th> -->
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>2021-2023</td>
                    <td><a href="https://inf.ethz.ch/" target="_blank">M.Sc. in Computer Science</a></td>
                    <td><a href="https://inf.ethz.ch/" target="_blank">ETH Zürich</a></td>
                    <!-- <td>TBD</td> -->
                  </tr>
                  <tr>
                    <td>2014-2018</td>
                    <td><a href="https://iitr.ac.in/Departments/Electrical%20Engineering%20Department/Home.html" target="_blank">B.Tech. in Electrical Engineering</a></td>
                    <td><a href="https://www.iitr.ac.in/" target="_blank">Indian Institute of Technology, Roorkee</a></td>
                    <!-- <td>TBD</td> -->
                  </tr>
                </tbody>
              </table>
          </div>
          </div>
        </div>
      </div>
     </section>
     <br/><br/>




     <section id="elem-section-work">
      <div class="container">
        <div class="columns">
          <div class="column is-12 is-offset-0 is-offset-1-mobile is-10-mobile">
            <div class="content">
              <div class="sk-section-heading">Work Experience</div>
              <!-- WORK EXP ITEM# -->
              <div class="box">
                <div class="sk-workexp-role">Research Assistant</div>
                <div class="sk-workexp-institution " >ETH Zürich, Product Development Group</div>
                <div class="sk-workexp-dates"> December 2023 - Present </div>
                <div class="sk-workexp-text">
                  Developing few-shot visual anomaly detection models for industrial components inspection.</div>
              </div>
            
            <!-- WORK EXP ITEM# -->
            <div class="box">
              <div class="sk-workexp-role">Master's Thesis Student</div>
              <div class="sk-workexp-institution " >Disney Research | Studios, Zurich, Switzerland</div>
              <div class="sk-workexp-dates"> March 2023 - September 2023</div>
              <div class="sk-workexp-text">
                Developed efficient transformer network for topology-independent shape modeling.</div>
            </div>

            <!-- WORK EXP ITEM# -->
            <div class="box">
              <div class="sk-workexp-role">Member of Technical Staff</div>
              <div class="sk-workexp-institution " >Oracle India Private Limited - Oracle Cloud AI Services (OCAS), Bengaluru, India</div>
              <div class="sk-workexp-dates"> October 2020 - September 2021</div>
              <div class="sk-workexp-text">
              In this role at OCAS, I worked on end-to-end experimentation with deep learning models for NLP, making them production
              ready and implementing APIs to expose them as cloud services.</div>
            
            </div>
            


            <!-- WORK EXP ITEM# -->
            <div class="box">
              <div class="sk-workexp-role">Software Developer</div>
              <div class="sk-workexp-institution " >Oracle India Private Limited - Oracle Applications Lab (OAL), Bengaluru, India</div>
              <div class="sk-workexp-dates"> 26<sup>th</sup> July 2018 - September 2020</div>
              <div class="sk-workexp-text">
                At OAL, I worked on developing cloud software solutions to streamline and optimize Supply Chain processes for Oracle's
                hardware business.</div>
            
            </div>

            <!-- WORK EXP ITEM# -->
            <div class="box">
              <div class="sk-workexp-role">Research Intern</div>
              <div class="sk-workexp-institution " >Department of Computer Science, Technical University of Munich, Munich, Germany</div>
              <div class="sk-workexp-dates"> 5<sup>th</sup> May 2017 - 15<sup>th</sup> July 2017</div>
              <div class="sk-workexp-text">
                I worked on the development of a Deep Learning based system to segment various structures in the infant-brain MRIs and mitigating the problems associated with isointense scans.</div>
            
            </div>

          </div>
        </div>
      </div>
      </div>
      </section>
      <br/><br/>

      
      <section id="elem-section-research">
        <div class="container">
          <div class="columns">
            <div class="column is-12 is-offset-0 is-offset-1-mobile is-10-mobile">
              <div class="content">
                <div class="sk-section-heading">Research Publications</div>
              <!-- WORK EXP ITEM# -->
              <div class="box">
                <div class="sk-workexp-role">InfiNet: Fully Convolutional Networks for Infant Brain MRI Segmentation</div>
                <div class="sk-workexp-dates">S. Kumar, S. Conjeti, A. G. Roy, C. Wachinger and N. Navab, "InfiNet: Fully convolutional networks for infant
                  brain MRI segmentation," 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), Washington,
                  DC, 2018, pp. 145-148.</div>
                <div>
                  <a href="https://ieeexplore.ieee.org/abstract/document/8363542" target="_blank"><span class="icon"><i class="fa fa-file-pdf"></i></span></a>
                </div>
                <div class="columns is-desktop">
                  <div class="column">
                    <figure class="image">
                      <img src="./res/data/portfolio/2018-08-00-INFINET/pipeline.png" alt="pipeline">
                    </figure>
                  </div>
                  <div class="column">We present a novel, parameter-efficient and practical fully
                    convolutional neural network architecture, termed InfiNet,
                    aimed at voxel-wise semantic segmentation of infant brain
                    MRI images at iso-intense stage, which can be easily extended for other segmentation tasks involving multi-modalities.
                    InfiNet consists of double encoder arms for T1 and T2 input
                    scans that feed into a joint-decoder arm that terminates in
                    the classification layer. The novelty of InfiNet lies in the
                    manner in which the decoder upsamples lower resolution input feature map(s) from multiple encoder arms. Specifically,
                    the pooled indices computed in the max-pooling layers of
                    each of the encoder blocks are related to the corresponding
                    decoder block to perform non-linear learning-free upsampling. The sparse maps are concatenated with intermediate
                    encoder representations (skip connections) and convolved
                    with trainable filters to produce dense feature maps. InfiNet
                    is trained end-to-end to optimize for the Generalized Dice
                    Loss, which is well-suited for high class imbalance. InfiNet
                    achieves the whole-volume segmentation in under 50 seconds
                    and we demonstrate competitive performance against multiple state-of-the art deep architectures and their multi-modal
                    variants.</div>
                </div>
              </div>
              <div class="box">
                <div class="sk-workexp-role">Learning Optimal Deep Projection of <sup>18</sup>F-FDG PET Imaging for Early Differential Diagnosis of Parkinsonian Syndromes</div>
                <div class="sk-workexp-dates">Kumar S. et al. (2018), "Learning Optimal Deep Projection of 18F-FDG PET Imaging for Early Differential Diagnosis of Parkinsonian Syndromes", Deep Learning in Medical Image Analysis 2018, ML-CDS 2018, Granada, Spain.
                  Lecture Notes in Computer Science, vol 11045. Springer, Cham</div>
                  <div>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-00889-5_26" target="_blank"><span class="icon"><i class="fa fa-file-pdf"></i></span></a>
                  </div>
                  <div class="columns is-desktop">
                    <div class="column">
                      <div><figure class="image">
                        <img src="./res/data/portfolio/2019-00-00-DPNN/pipeline_arch.png" alt="pipeline">
                      </figure></div>
                      <!-- <div><figure class="image">
                        <img src="./res/data/portfolio/2019-00-00-DPNN/pipeline_example.png" alt="pipeline">
                      </figure></div> -->
                    </div>
                    <div class="column">Several diseases of parkinsonian syndromes present similar symptoms at early stage and no objective widely used diagnostic methods have been approved until now. Positron emission tomography (PET) with 18
                      F-FDG was shown to be able to assess early neuronal dysfunction of synucleinopathies and tauopathies. Tensor factorization (TF) based approaches have been applied to identify characteristic metabolic patterns for differential diagnosis. However, these conventional dimension-reduction strategies assume linear or multi-linear relationships inside data, and are therefore insufficient to distinguish nonlinear metabolic differences between various parkinsonian syndromes. In this paper, we propose a Deep Projection Neural Network (DPNN) to identify characteristic metabolic pattern for early differential diagnosis of parkinsonian syndromes. We draw our inspiration from the existing TF methods. The network consists of a (i) compression part: which uses a deep network to learn optimal 2D projections of 3D scans, and a (ii) classification part: which maps the 2D projections to labels. The compression part can be pre-trained using surplus unlabelled datasets. Also, as the classification part operates on these 2D projections, it can be trained end-to-end effectively with limited labelled data, in contrast to 3D approaches. We show that DPNN is more effective in comparison to existing state-of-the-art and plausible baselines.
                      
                      </div>
                  </div>
              </div>
  
              
  
            </div>
          </div>
        </div>
        </div>
        </section>
        <br/><br/>
     

     <!-- BEGIN: PORTFOLIO -->
     
     <section id="elem-section-projects">
       <div class="container">
        <div class="columns">
          <div class="column is-12 is-offset-0 is-offset-1-mobile is-10-mobile">
            <div class="content">
              <div class="sk-section-heading">Projects</div>

             <!-- PORTFOLIO ENTRY BEGIN -->
             <div class="box">
              <div class="sk-portfolio-title">Design and Training of Efficient Transformer Networks</div>
              
              <div class="sk-portfolio-institution " > Neural Network Optimization Group@Disney Research | Studios & Computer Graphics Lab, ETH Zurich</div>
              <div class="sk-portfolio-dates">March 2023 - September 2023</div>
              <hr/>
              <div class="columns">
                <div class="sk-portfolio-intro-image column">
                  <figure class="image">
                    <img src="./res/data/portfolio/2023-09-00-A2S/output_sample.gif" alt="pipeline">
                  </figure>
                  </div>
                  <div class="sk-portfolio-info column">To handle large number of input tokens efficiently, more efficient variant of attention based model is needed with a reasonable trade-off between the performance and efficiency. In this work, a novel attention mechanism is developed, which is tailored to the requirements of shape-modeling and processing point clouds. It shows improved results on modeling hand-poses compared to the efficient attention models like XCA and LUNA. The proposed method also allows the user to inject prior information directly to the attention module, which enables artistic control of very articulated motion.</div>
              </div>
              
            

            

            </div>
            <!-- PORTFOLIO ENTRY END -->
              
            <!-- PORTFOLIO ENTRY BEGIN -->
            <div class="box">
              <div class="sk-portfolio-title">Extracting Respiratory Rate with Uncertainty Estimates from Photoplethysmograph Using Probabilistic Deep Neural Networks</div>
              
              <div class="sk-portfolio-institution " >Sensing Interaction & Perception Lab, ETH Zurich</div>
              <div class="sk-portfolio-dates">October 2022 - December 2022</div>
              <hr/>
              <div class="columns">
                <div class="sk-portfolio-intro-image column">
                  <figure class="image">
                    <img src="./res/data/portfolio/2022-12-00-RESPR/teaser.jpg" alt="pipeline">
                  </figure>
                  </div>
                  <div class="sk-portfolio-info column">Assessment of predictive uncertainty is of great importance
                    and especially so for medical applications. This study explores
                    the processing of photoplethysmogram (PPG) signals using
                    Probabilistic Deep Neural Networks for estimating the res-
                    piratory rate and the associated uncertainty in the prediction.
                    The study is conducted on two publicly available datasets:
                    Capnobase and BIDMC. A residual 1D-Convolutional Neural
                    Network (CNN) with Dropout layers is used in mean-variance
                    estimation (MVE) setting to get the respiratory rate and un-
                    certainty estimates. We also perform Contrastive Learning for
                    pretraining the network and assessing its effect on uncertainty
                    and predictive performance. We consider predictions with an
                    uncertainty below the threshold of 4 breaths per min (bpm)
                    to be reliable. The model retains 73% windows with reliable
                    estimates and a mean absolute error (MAE) of 3.3 bpm on
                    Capnobase, and 72.3% retained windows with MAE of 2.9 on
                    BIDMC dataset. To evaluate the uncertainty estimates of our
                    trained model, we also analyze the change of the MAE of our
                    model on both datasets. We find that for the BIDMC dataset,
                    the MAE increases as the uncertainty increases showing the
                    usefulness of our approach. For the Capnobase dataset, we
                    did not find an evident pattern, which may be a result of the
                    smaller size and imbalance in this dataset.</div>
              </div>
              
            

            

            </div>
            <!-- PORTFOLIO ENTRY END -->

              
            <!-- PORTFOLIO ENTRY BEGIN -->
            <div class="box">
              <div class="sk-portfolio-title">Improving Relative Pose Estimation by Estimating Gravity</div>
              
              <div class="sk-portfolio-institution " >3D-Vision , ETH Zurich</div>
              <div class="sk-portfolio-dates">March 2022 - May 2022</div>
              <hr/>
              <div class="columns">
                <div class="sk-portfolio-intro-image column">
                  <figure class="image">
                    <img src="./res/data/portfolio/2022-00-00-3DVISION-GRAVITY/pipeline.png" alt="pipeline">
                  </figure>
                  </div>
                  <div class="sk-portfolio-info column">Estimating the relative pose of cameras is an important problem in 3D vision applications. It is used to create 3D models from images and for mapping in robotic applications. Especially for real-time applications, it is important to have fast and robust algorithms for relative pose estimation. For calibrated camera settings, without further constraints, the relative pose can be estimated using a 5-point solver. By using the gravity vector of the images, the problem reduces to 3 DoF . This allows to reduce the sample size and thereby decrease the required amount of RANSAC iterations exponentially. In this work we develop a pipeline to estimate the relative pose using '3-point (with gravity)' and '5-point' estimators, and compare their performance on the ScanNet dataset. We perform tests on more than 11000 image pairs from 260 indoor scenes and varying amount of errors in the gravity estimates.</div>
              </div>
              
            

            

            </div>
            <!-- PORTFOLIO ENTRY END -->



              
           
        </div>
      </div>
        </div>
        
      </div>
      
      </section>
    
   

     <!-- END: PORTFOLIO -->

      <div>
        <hr/>
        <hr/>
      </div>

  </body>
</html>